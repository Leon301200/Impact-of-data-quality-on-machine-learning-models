{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T21:12:54.484778Z",
     "start_time": "2024-08-20T21:12:53.609778Z"
    }
   },
   "source": [
    "# Importation des librairies\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T21:13:01.574820Z",
     "start_time": "2024-08-20T21:13:01.571936Z"
    }
   },
   "cell_type": "code",
   "source": "pd.set_option('future.no_silent_downcasting', True)",
   "id": "98a51fd61ae22b04",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T21:13:02.143089Z",
     "start_time": "2024-08-20T21:13:02.102002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_csv_files_to_dict(base_path, dimension, file_prefix, missing_percentages, strategies=None):\n",
    "    dataframes_dict = {}\n",
    "\n",
    "    for percentage in missing_percentages:\n",
    "        percentage_key = f\"{int(percentage * 100)}%\"\n",
    "\n",
    "        if dimension == 'Completeness':\n",
    "            dataframes_dict[percentage_key] = {}\n",
    "\n",
    "            if strategies is not None:\n",
    "                for strategy_name, strategy_func, subfolder in strategies:\n",
    "                    file_path = f\"{base_path}/{dimension}/{subfolder}/{file_prefix}_{percentage_key}.csv\"\n",
    "\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        dataframes_dict[percentage_key][strategy_name] = df\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"File not found: {file_path}\")\n",
    "                        dataframes_dict[percentage_key][strategy_name] = None\n",
    "            else:\n",
    "                print(\"No strategies provided for Completeness dimension.\")\n",
    "        elif dimension == 'Unicity':\n",
    "            file_path = f\"{base_path}/{dimension}/{file_prefix}_{percentage_key}_2x.csv\"\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                dataframes_dict[percentage_key] = df\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                dataframes_dict[percentage_key] = None\n",
    "        else:\n",
    "            file_path = f\"{base_path}/{dimension}/{file_prefix}_{percentage_key}.csv\"\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                dataframes_dict[percentage_key] = df\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                dataframes_dict[percentage_key] = None\n",
    "\n",
    "    return dataframes_dict\n",
    "\n",
    "def update_json_results(output_path, model_name, pollution_percentage, results):\n",
    "    # Charger le fichier JSON existant, ou initialiser une nouvelle structure si le fichier n'existe pas\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, 'r') as json_file:\n",
    "            results_dict = json.load(json_file)\n",
    "    else:\n",
    "        results_dict = {\n",
    "            \"models\": []\n",
    "        }\n",
    "\n",
    "    # Trouver ou ajouter l'entrée pour le modèle spécifié\n",
    "    model_entry = next((model for model in results_dict[\"models\"] if model[\"model\"] == model_name), None)\n",
    "\n",
    "    if not model_entry:\n",
    "        model_entry = {\n",
    "            \"model\": model_name,\n",
    "            \"pollution_metrics\": []\n",
    "        }\n",
    "        results_dict[\"models\"].append(model_entry)\n",
    "\n",
    "    # Chercher si le pourcentage de pollution existe déjà pour ce modèle\n",
    "    existing_entry = next((item for item in model_entry[\"pollution_metrics\"] if item[\"pollution_percentage\"] == pollution_percentage), None)\n",
    "\n",
    "    if existing_entry:\n",
    "        # Si le pourcentage de pollution existe, remplacer les métriques\n",
    "        existing_entry[\"metrics\"] = results\n",
    "    else:\n",
    "        # Sinon, ajouter une nouvelle entrée pour ce pourcentage\n",
    "        model_entry[\"pollution_metrics\"].append({\n",
    "            \"pollution_percentage\": pollution_percentage,\n",
    "            \"metrics\": results\n",
    "        })\n",
    "\n",
    "    # Écrire les résultats mis à jour dans le fichier JSON\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(results_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "\n",
    "def update_json_results_completeness(output_path, model_name, strategy, pollution_percentage, results):\n",
    "    # Charger le fichier JSON existant, ou initialiser une nouvelle structure si le fichier n'existe pas\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, 'r') as json_file:\n",
    "            results_dict = json.load(json_file)\n",
    "    else:\n",
    "        results_dict = {\n",
    "            \"models\": [\n",
    "                {\n",
    "                    \"model\": model_name,\n",
    "                    \"imputation_strategies\": []\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Trouver ou ajouter l'entrée pour le modèle spécifié\n",
    "    model_entry = next((model for model in results_dict[\"models\"] if model[\"model\"] == model_name), None)\n",
    "\n",
    "    if not model_entry:\n",
    "        model_entry = {\n",
    "            \"model\": model_name,\n",
    "            \"imputation_strategies\": []\n",
    "        }\n",
    "        results_dict[\"models\"].append(model_entry)\n",
    "\n",
    "    # Trouver ou créer l'entrée pour la stratégie d'imputation actuelle\n",
    "    strategy_entry = next((item for item in model_entry[\"imputation_strategies\"] if item[\"strategy\"] == strategy), None)\n",
    "\n",
    "    if not strategy_entry:\n",
    "        # Ajouter une nouvelle stratégie d'imputation si elle n'existe pas encore\n",
    "        strategy_entry = {\n",
    "            \"strategy\": strategy,\n",
    "            \"pollution_metrics\": []\n",
    "        }\n",
    "        model_entry[\"imputation_strategies\"].append(strategy_entry)\n",
    "\n",
    "    # Vérifier si le pourcentage de pollution existe déjà pour cette stratégie\n",
    "    existing_entry = next((item for item in strategy_entry[\"pollution_metrics\"] if item[\"pollution_percentage\"] == pollution_percentage), None)\n",
    "\n",
    "    if existing_entry:\n",
    "        # Si le pourcentage de pollution existe, remplacer les métriques\n",
    "        existing_entry[\"metrics\"] = results\n",
    "    else:\n",
    "        # Sinon, ajouter une nouvelle entrée pour ce pourcentage\n",
    "        strategy_entry[\"pollution_metrics\"].append({\n",
    "            \"pollution_percentage\": pollution_percentage,\n",
    "            \"metrics\": results\n",
    "        })\n",
    "\n",
    "    # Écrire les résultats mis à jour dans le fichier JSON\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(results_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "\n",
    "def prepare_fps_data(fps_df):\n",
    "    fps_df['GpuOpenCL'] = fps_df['GpuOpenCL'].astype(str)\n",
    "    fps_df['GpuShaderModel'] = fps_df['GpuShaderModel'].astype(str)\n",
    "    fps_df = pd.get_dummies(fps_df, drop_first=True)\n",
    "\n",
    "    # Séparer les variables indépendantes (X) de la variable cible (y)\n",
    "    X = fps_df.drop('FPS', axis=1)\n",
    "    y = fps_df['FPS']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    model = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10, n_jobs=-1)  # Utilisation de plusieurs cœurs, moins d'arbres et profondeur limitée\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  # Réduction du nombre de splits à 3\n",
    "\n",
    "    scoring = {\n",
    "        'mse': make_scorer(mean_squared_error),\n",
    "        'mae': make_scorer(mean_absolute_error),\n",
    "        'r2': make_scorer(r2_score)\n",
    "    }\n",
    "    cv_results = cross_validate(model, X, y, cv=kfold, scoring=scoring, n_jobs=-1)  # Utilisation de la parallélisation pour le cross-validation\n",
    "\n",
    "    results = {\n",
    "        \"mean_squared_error\": cv_results['test_mse'].mean(),\n",
    "        \"mean_absolute_error\": cv_results['test_mae'].mean(),\n",
    "        \"r2_score\": cv_results['test_r2'].mean()\n",
    "    }\n",
    "\n",
    "    return results"
   ],
   "id": "f5811482999ec28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Completeness",
   "id": "e597de1b6946bdd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T17:13:29.872443Z",
     "start_time": "2024-08-20T15:21:53.871317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_percentages = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# Strategy :\n",
    "strategy_delete = {\n",
    "    'numerical': 'delete',\n",
    "    'categorical': 'delete'\n",
    "}\n",
    "\n",
    "strategy_mean_mode = {\n",
    "    'numerical': 'mean',\n",
    "    'categorical': 'mode'\n",
    "}\n",
    "\n",
    "strategy_median_new = {\n",
    "    'numerical': 'median',\n",
    "    'categorical': 'new'\n",
    "}\n",
    "\n",
    "strategy_decision_tree = {\n",
    "    'numerical': 'decision_tree',\n",
    "    'categorical': 'decision_tree'\n",
    "}\n",
    "\n",
    "strategy_mean_new = {\n",
    "    'numerical': 'mean',\n",
    "    'categorical': 'new'\n",
    "}\n",
    "\n",
    "strategy_knn_mode = {\n",
    "    'numerical': 'knn',\n",
    "    'categorical': 'mode'\n",
    "}\n",
    "\n",
    "strategies = [\n",
    "    (\"Mean and Mode\", strategy_mean_mode, \"Mean and Mode\"),\n",
    "    (\"Median and New\", strategy_median_new, \"Median and New\"),\n",
    "    (\"Decision Tree\", strategy_decision_tree, \"Decision Tree\"),\n",
    "    (\"Mean and New\", strategy_mean_new, \"Mean and New\")\n",
    "]\n",
    "\n",
    "fps_df_dict = read_csv_files_to_dict('../../Data/Regression/fps in video games', 'Completeness', 'fps', missing_percentages, strategies)\n",
    "\n",
    "# Chemin du fichier JSON où les résultats seront enregistrés\n",
    "output_path = \"../../Results/FPS in video games/Completeness.json\"\n",
    "\n",
    "# Boucle sur les DataFrames pour chaque pourcentage de pollution\n",
    "for key, fps_df_strategies in fps_df_dict.items():\n",
    "    for strategy_name, fps_df in fps_df_strategies.items():\n",
    "        X, y = prepare_fps_data(fps_df)\n",
    "\n",
    "        results = train_and_evaluate(X, y)\n",
    "\n",
    "        # Extraire le pourcentage de pollution à partir de la clé\n",
    "        pollution_percentage = float(key.replace('%', ''))\n",
    "\n",
    "        # Mise à jour des résultats dans le fichier JSON en utilisant la fonction\n",
    "        update_json_results_completeness(output_path, \"Random Forest\", strategy_name, pollution_percentage, results)"
   ],
   "id": "ecb4d7f27eeaa4b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/3494575585.py:15: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../Results/FPS in video games/Completeness.json\n",
      "Results saved to ../../Results/FPS in video games/Completeness.json\n",
      "Results saved to ../../Results/FPS in video games/Completeness.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 52\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m strategy_name, fps_df \u001B[38;5;129;01min\u001B[39;00m fps_df_strategies\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     50\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m prepare_fps_data(fps_df)\n\u001B[0;32m---> 52\u001B[0m     results \u001B[38;5;241m=\u001B[39m train_and_evaluate(X, y)\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;66;03m# Extraire le pourcentage de pollution à partir de la clé\u001B[39;00m\n\u001B[1;32m     55\u001B[0m     pollution_percentage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(key\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "Cell \u001B[0;32mIn[6], line 155\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[0;34m(X, y)\u001B[0m\n\u001B[1;32m    148\u001B[0m kfold \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m    150\u001B[0m scoring \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    151\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m: make_scorer(mean_squared_error),\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m: make_scorer(mean_absolute_error),\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m: make_scorer(r2_score)\n\u001B[1;32m    154\u001B[0m }\n\u001B[0;32m--> 155\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m cross_validate(model, X, y, cv\u001B[38;5;241m=\u001B[39mkfold, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m    157\u001B[0m results \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_squared_error\u001B[39m\u001B[38;5;124m\"\u001B[39m: cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_mse\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean(),\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_absolute_error\u001B[39m\u001B[38;5;124m\"\u001B[39m: cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_mae\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean(),\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr2_score\u001B[39m\u001B[38;5;124m\"\u001B[39m: cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_r2\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m    161\u001B[0m }\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:423\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    422\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 423\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    424\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    425\u001B[0m         clone(estimator),\n\u001B[1;32m    426\u001B[0m         X,\n\u001B[1;32m    427\u001B[0m         y,\n\u001B[1;32m    428\u001B[0m         scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[1;32m    429\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[1;32m    430\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[1;32m    431\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    432\u001B[0m         parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    433\u001B[0m         fit_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit,\n\u001B[1;32m    434\u001B[0m         score_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mscorer\u001B[38;5;241m.\u001B[39mscore,\n\u001B[1;32m    435\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n\u001B[1;32m    436\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    437\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n\u001B[1;32m    438\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[1;32m    439\u001B[0m     )\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[1;32m    441\u001B[0m )\n\u001B[1;32m    443\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    445\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     73\u001B[0m )\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    886\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 888\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    891\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    892\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    478\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[1;32m    481\u001B[0m ]\n\u001B[1;32m    483\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[1;32m    486\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[0;32m--> 489\u001B[0m trees \u001B[38;5;241m=\u001B[39m Parallel(\n\u001B[1;32m    490\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs,\n\u001B[1;32m    491\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    492\u001B[0m     prefer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthreads\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    493\u001B[0m )(\n\u001B[1;32m    494\u001B[0m     delayed(_parallel_build_trees)(\n\u001B[1;32m    495\u001B[0m         t,\n\u001B[1;32m    496\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbootstrap,\n\u001B[1;32m    497\u001B[0m         X,\n\u001B[1;32m    498\u001B[0m         y,\n\u001B[1;32m    499\u001B[0m         sample_weight,\n\u001B[1;32m    500\u001B[0m         i,\n\u001B[1;32m    501\u001B[0m         \u001B[38;5;28mlen\u001B[39m(trees),\n\u001B[1;32m    502\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    503\u001B[0m         class_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_weight,\n\u001B[1;32m    504\u001B[0m         n_samples_bootstrap\u001B[38;5;241m=\u001B[39mn_samples_bootstrap,\n\u001B[1;32m    505\u001B[0m         missing_values_in_feature_mask\u001B[38;5;241m=\u001B[39mmissing_values_in_feature_mask,\n\u001B[1;32m    506\u001B[0m     )\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trees)\n\u001B[1;32m    508\u001B[0m )\n\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     73\u001B[0m )\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:192\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m class_weight \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced_subsample\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    190\u001B[0m         curr_sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m compute_sample_weight(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced\u001B[39m\u001B[38;5;124m\"\u001B[39m, y, indices\u001B[38;5;241m=\u001B[39mindices)\n\u001B[0;32m--> 192\u001B[0m     tree\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[1;32m    193\u001B[0m         X,\n\u001B[1;32m    194\u001B[0m         y,\n\u001B[1;32m    195\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39mcurr_sample_weight,\n\u001B[1;32m    196\u001B[0m         check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    197\u001B[0m         missing_values_in_feature_mask\u001B[38;5;241m=\u001B[39mmissing_values_in_feature_mask,\n\u001B[1;32m    198\u001B[0m     )\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     tree\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[1;32m    201\u001B[0m         X,\n\u001B[1;32m    202\u001B[0m         y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    205\u001B[0m         missing_values_in_feature_mask\u001B[38;5;241m=\u001B[39mmissing_values_in_feature_mask,\n\u001B[1;32m    206\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Impact-of-data-quality-on-machine-learning-models/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[1;32m    463\u001B[0m         splitter,\n\u001B[1;32m    464\u001B[0m         min_samples_split,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    469\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[1;32m    470\u001B[0m     )\n\u001B[0;32m--> 472\u001B[0m builder\u001B[38;5;241m.\u001B[39mbuild(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Consistent Representation",
   "id": "3d6c1268b2ee65e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-20T17:45:24.529118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pollution_percentage_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "fps_df_dict = read_csv_files_to_dict('../../Data/Regression/fps in video games', 'Consistent Representation', 'fps', pollution_percentage_levels)\n",
    "\n",
    "# Chemin du fichier JSON où les résultats seront enregistrés\n",
    "output_path = \"../../Results/FPS in video games/Consistent Representation.json\"\n",
    "\n",
    "# Boucle sur les DataFrames pour chaque pourcentage de pollution\n",
    "for key, fps_df in fps_df_dict.items():\n",
    "    X, y = prepare_fps_data(fps_df)\n",
    "\n",
    "    results = train_and_evaluate(X, y)\n",
    "\n",
    "    # Extraire le pourcentage de pollution à partir de la clé\n",
    "    pollution_percentage = float(key.replace('%', ''))\n",
    "\n",
    "    # Mise à jour des résultats dans le fichier JSON\n",
    "    update_json_results(output_path, \"Random Forest\", pollution_percentage, results)"
   ],
   "id": "c9d64fb4f9184d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_11879/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../Results/FPS in video games/Consistent Representation.json\n",
      "Results saved to ../../Results/FPS in video games/Consistent Representation.json\n",
      "Results saved to ../../Results/FPS in video games/Consistent Representation.json\n",
      "Results saved to ../../Results/FPS in video games/Consistent Representation.json\n",
      "Results saved to ../../Results/FPS in video games/Consistent Representation.json\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Accuracy",
   "id": "571f70ebb5af73b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T21:45:52.592965Z",
     "start_time": "2024-08-20T21:13:30.244482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pollution_percentage_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "fps_df_dict = read_csv_files_to_dict('../../Data/Regression/fps in video games', 'Feature Accuracy', 'fps', pollution_percentage_levels)\n",
    "\n",
    "# Chemin du fichier JSON où les résultats seront enregistrés\n",
    "output_path = \"../../Results/FPS in video games/Feature Accuracy.json\"\n",
    "\n",
    "# Boucle sur les DataFrames pour chaque pourcentage de pollution\n",
    "for key, fps_df in fps_df_dict.items():\n",
    "    X, y = prepare_fps_data(fps_df)\n",
    "\n",
    "    results = train_and_evaluate(X, y)\n",
    "\n",
    "    # Extraire le pourcentage de pollution à partir de la clé\n",
    "    pollution_percentage = float(key.replace('%', ''))\n",
    "\n",
    "    # Mise à jour des résultats dans le fichier JSON\n",
    "    update_json_results(output_path, \"Random Forest\", pollution_percentage, results)"
   ],
   "id": "f2320dba83979578",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Feature Accuracy.json\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Target Accuracy",
   "id": "e7682e7177ca29c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T21:54:50.364436Z",
     "start_time": "2024-08-20T21:45:52.594401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pollution_percentage_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "fps_df_dict = read_csv_files_to_dict('../../Data/Regression/fps in video games', 'Target Accuracy', 'fps', pollution_percentage_levels)\n",
    "\n",
    "# Chemin du fichier JSON où les résultats seront enregistrés\n",
    "output_path = \"../../Results/FPS in video games/Target Accuracy.json\"\n",
    "\n",
    "# Boucle sur les DataFrames pour chaque pourcentage de pollution\n",
    "for key, fps_df in fps_df_dict.items():\n",
    "    X, y = prepare_fps_data(fps_df)\n",
    "\n",
    "    results = train_and_evaluate(X, y)\n",
    "\n",
    "    # Extraire le pourcentage de pollution à partir de la clé\n",
    "    pollution_percentage = float(key.replace('%', ''))\n",
    "\n",
    "    # Mise à jour des résultats dans le fichier JSON\n",
    "    update_json_results(output_path, \"Random Forest\", pollution_percentage, results)"
   ],
   "id": "eb2be8ef4e983d92",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:33: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n",
      "Results saved to ../../Results/FPS in video games/Target Accuracy.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unicity",
   "id": "626f785bde8c629f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:09:28.135469Z",
     "start_time": "2024-08-20T21:54:50.365669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pollution_percentage_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "fps_df_dict = read_csv_files_to_dict('../../Data/Regression/fps in video games', 'Unicity', 'fps', pollution_percentage_levels)\n",
    "\n",
    "# Chemin du fichier JSON où les résultats seront enregistrés\n",
    "output_path = \"../../Results/FPS in video games/Unicity.json\"\n",
    "\n",
    "# Boucle sur les DataFrames pour chaque pourcentage de pollution\n",
    "for key, fps_df in fps_df_dict.items():\n",
    "    X, y = prepare_fps_data(fps_df)\n",
    "\n",
    "    results = train_and_evaluate(X, y)\n",
    "\n",
    "    # Extraire le pourcentage de pollution à partir de la clé\n",
    "    pollution_percentage = float(key.replace('%', ''))\n",
    "\n",
    "    # Mise à jour des résultats dans le fichier JSON\n",
    "    update_json_results(output_path, \"Random Forest\", pollution_percentage, results)"
   ],
   "id": "396234d9cb63db12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_18305/1602015047.py:25: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n",
      "Results saved to ../../Results/FPS in video games/Unicity.json\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f143abbe8314f6cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
