{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:35:06.607182Z",
     "start_time": "2024-08-17T22:35:05.954845Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T00:20:08.207982Z",
     "start_time": "2024-08-18T00:20:08.198275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_numerical_by_delete(df):\n",
    "    df_cleaned = df.copy()\n",
    "    numerical_cols = df_cleaned.select_dtypes(include=np.number).columns\n",
    "    df_cleaned = df_cleaned.dropna(subset=numerical_cols)\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def impute_numerical_by_mean(df):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed[df_imputed.select_dtypes(include='number').columns] = imputer.fit_transform(\n",
    "        df_imputed.select_dtypes(include='number'))\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_numerical_by_median(df):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_imputed[df_imputed.select_dtypes(include='number').columns] = imputer.fit_transform(\n",
    "        df_imputed.select_dtypes(include='number'))\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_numerical_by_knn(df):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_imputed[df_imputed.select_dtypes(include='number').columns] = imputer.fit_transform(\n",
    "        df_imputed.select_dtypes(include='number'))\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_numerical_by_multiple(df):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = IterativeImputer()\n",
    "    df_imputed[df_imputed.select_dtypes(include='number').columns] = imputer.fit_transform(\n",
    "        df_imputed.select_dtypes(include='number'))\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_numerical_by_decision_tree(df):\n",
    "    df_imputed = df.copy()\n",
    "    numerical_columns = df_imputed.select_dtypes(include='number').columns\n",
    "    categorical_columns = df_imputed.select_dtypes(include='object').columns\n",
    "\n",
    "    for col in numerical_columns:\n",
    "        if df_imputed[col].isnull().sum() > 0:\n",
    "            # Separate known and unknown data\n",
    "            known_data = df_imputed[df_imputed[col].notna()]\n",
    "            unknown_data = df_imputed[df_imputed[col].isna()]\n",
    "\n",
    "            if not unknown_data.empty:\n",
    "                # Convert categorical columns to dummies\n",
    "                known_data_dummies = pd.get_dummies(known_data, columns=categorical_columns, drop_first=False)\n",
    "                unknown_data_dummies = pd.get_dummies(unknown_data, columns=categorical_columns, drop_first=False)\n",
    "\n",
    "                # Align the columns to ensure they match\n",
    "                known_data_dummies, unknown_data_dummies = known_data_dummies.align(unknown_data_dummies, join='left', axis=1, fill_value=0)\n",
    "\n",
    "                # Train the model on known data\n",
    "                model = DecisionTreeRegressor()\n",
    "                model.fit(known_data_dummies.drop(columns=[col]), known_data[col])\n",
    "\n",
    "                # Predict missing values and replace them\n",
    "                df_imputed.loc[df_imputed[col].isna(), col] = model.predict(unknown_data_dummies.drop(columns=[col]))\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# Imputation pour les données catégoriques\n",
    "def impute_categorical_by_delete(df):\n",
    "    df_cleaned = df.copy()\n",
    "    categorical_cols = df_cleaned.select_dtypes(include='object').columns\n",
    "    df_cleaned = df_cleaned.dropna(subset=categorical_cols)\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def impute_categorical_by_mode(df):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_imputed[df_imputed.select_dtypes(include='object').columns] = imputer.fit_transform(\n",
    "        df_imputed.select_dtypes(include='object'))\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_categorical_by_new_category(df):\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed = df_imputed.fillna('Missing')\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_categorical_by_hot_deck(df):\n",
    "    df_imputed = df.copy()\n",
    "    for col in df_imputed.columns:\n",
    "        missing_indices = df_imputed[col].isna()\n",
    "        if missing_indices.any():\n",
    "            available_values = df_imputed[col].dropna().values\n",
    "            imputed_values = np.random.choice(available_values, size=missing_indices.sum())\n",
    "            df_imputed.loc[missing_indices, col] = imputed_values\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_categorical_by_decision_tree(df):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    object_columns = df_imputed.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in object_columns:\n",
    "        if df_imputed[col].isnull().sum() > 0:\n",
    "            # Split the DataFrame into two sets: with and without missing values for the current column\n",
    "            df_missing = df_imputed[df_imputed[col].isnull()]\n",
    "            df_not_missing = df_imputed[~df_imputed[col].isnull()]\n",
    "\n",
    "            # If all values are missing, we cannot predict anything\n",
    "            if df_not_missing.empty:\n",
    "                continue\n",
    "\n",
    "            # Define features (X) and target (y)\n",
    "            X = df_not_missing.drop(columns=[col])\n",
    "            y = df_not_missing[col].astype(str)  # Ensure the target is categorical\n",
    "\n",
    "            # Encode the remaining object columns\n",
    "            X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "            # Encode the missing set and align columns\n",
    "            X_missing = pd.get_dummies(df_missing.drop(columns=[col]), drop_first=True)\n",
    "\n",
    "            # Align columns to ensure consistency\n",
    "            X, X_missing = X.align(X_missing, join='left', axis=1, fill_value=0)\n",
    "\n",
    "            # Ensure there are no duplicated columns\n",
    "            X = X.loc[:, ~X.columns.duplicated()]\n",
    "            X_missing = X_missing.loc[:, ~X_missing.columns.duplicated()]\n",
    "\n",
    "            # Create and train the model\n",
    "            model = DecisionTreeClassifier(random_state=42)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            # Predict the missing values\n",
    "            df_imputed.loc[df_imputed[col].isnull(), col] = model.predict(X_missing)\n",
    "\n",
    "    return df_imputed"
   ],
   "id": "16f001b8a3164c30",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHARGEMENTS DES DONNEES",
   "id": "82dd3577936034b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:38:31.973573Z",
     "start_time": "2024-08-17T22:38:30.458600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargement des DataSets\n",
    "fps_df = pd.read_csv('../../../Data/Regression/fps in video games/fps-in-video-games_clean.csv', )\n",
    "heart_df = pd.read_csv('../../../Data/Classification/Indicators of Heart Disease/heart_2022_no_nans_clean.csv')\n",
    "retail_df = pd.read_csv('../../../Data/Clustering/retail Data/retail_data_clean.csv')"
   ],
   "id": "c621265dc0224f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/3500090452.py:2: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fps_df = pd.read_csv('../../../Data/Regression/fps in video games/fps-in-video-games_clean.csv')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SUPPRESSION DES DONNEES",
   "id": "3a92d7c7c1026c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:38:35.462868Z",
     "start_time": "2024-08-17T22:38:35.458861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def introduce_missing_values_mcar(df, missing_percentages, target=None):\n",
    "    # Vérifie que les pourcentages sont valides\n",
    "    if not all(0 <= p <= 1 for p in missing_percentages):\n",
    "        raise ValueError(\"Les pourcentages doivent être entre 0 et 1.\")\n",
    "\n",
    "    # Si une target est spécifiée, vérifie que la colonne existe dans le DataFrame\n",
    "    if target and target not in df.columns:\n",
    "        raise ValueError(f\"La colonne target '{target}' n'existe pas dans le DataFrame.\")\n",
    "\n",
    "    df_dict = {}\n",
    "\n",
    "    for percentage in missing_percentages:\n",
    "        df_missing = df.copy()\n",
    "        # Pour chaque colonne du DataFrame\n",
    "        for col in df.columns:\n",
    "            # Si une target est spécifiée, on exclut cette colonne\n",
    "            if target and col == target:\n",
    "                continue  # On saute la colonne target\n",
    "            # Calcule le nombre de valeurs à remplacer par NaN\n",
    "            n_missing = int(np.floor(percentage * df.shape[0]))\n",
    "            # Sélectionne aléatoirement les index des valeurs à remplacer\n",
    "            missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "            # Remplace les valeurs par NaN\n",
    "            df_missing.loc[missing_indices, col] = np.nan\n",
    "\n",
    "        df_dict[f\"{int(percentage * 100)}%\"] = df_missing\n",
    "\n",
    "    return df_dict"
   ],
   "id": "725440d5fef5f958",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:38:43.740596Z",
     "start_time": "2024-08-17T22:38:37.737441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Liste des pourcentages de valeurs manquantes à introduire\n",
    "missing_percentages = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Génération des DataFrames avec valeurs manquantes\n",
    "fps_df_with_missing = introduce_missing_values_mcar(fps_df, missing_percentages, 'FPS')\n",
    "heart_df_with_missing = introduce_missing_values_mcar(heart_df, missing_percentages, 'HadHeartAttack')\n",
    "retail_df_with_missing = introduce_missing_values_mcar(retail_df, missing_percentages)"
   ],
   "id": "f34db870e6774e1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:39:33.367378Z",
     "start_time": "2024-08-17T22:38:46.013251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enregistrement des DataFrames générés\n",
    "for key, value in fps_df_with_missing.items():\n",
    "    value.to_csv(f\"../../../Data/Regression/fps in video games/Completeness/NaN/fps_{key}.csv\", index=False)\n",
    "\n",
    "for key, value in heart_df_with_missing.items():\n",
    "    value.to_csv(f\"../../../Data/Classification/Indicators of Heart Disease/Completeness/NaN/heart_{key}.csv\", index=False)\n",
    "\n",
    "for key, value in retail_df_with_missing.items():\n",
    "    value.to_csv(f\"../../../Data/Clustering/retail Data/Completeness/NaN/retail_{key}.csv\", index=False)"
   ],
   "id": "369eee28d4a1070",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correction des données avec differentes Strategies",
   "id": "ee598ad14739a92a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:39:46.862402Z",
     "start_time": "2024-08-17T22:39:46.857352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_dataset(df, strategy):\n",
    "    df_imputed = df.copy()\n",
    "    # Impute numerical columns\n",
    "    if strategy['numerical'] == 'delete':\n",
    "        df_imputed = impute_numerical_by_delete(df_imputed)\n",
    "    elif strategy['numerical'] == 'mean':\n",
    "        df_imputed = impute_numerical_by_mean(df_imputed)\n",
    "    elif strategy['numerical'] == 'median':\n",
    "        df_imputed = impute_numerical_by_median(df_imputed)\n",
    "    elif strategy['numerical'] == 'knn':\n",
    "        df_imputed = impute_numerical_by_knn(df_imputed)\n",
    "    elif strategy['numerical'] == 'multiple':\n",
    "        df_imputed = impute_numerical_by_multiple(df_imputed)\n",
    "    elif strategy['numerical'] == 'decision_tree':\n",
    "        df_imputed = impute_numerical_by_decision_tree(df_imputed)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown numerical imputation strategy\")\n",
    "\n",
    "    # Impute categorical columns\n",
    "    if strategy['categorical'] == 'delete':\n",
    "        df_imputed = impute_categorical_by_delete(df_imputed)\n",
    "    elif strategy['categorical'] == 'mode':\n",
    "        df_imputed = impute_categorical_by_mode(df_imputed)\n",
    "    elif strategy['categorical'] == 'new':\n",
    "        df_imputed = impute_categorical_by_new_category(df_imputed)\n",
    "    elif strategy['categorical'] == 'hot_deck':\n",
    "        df_imputed = impute_categorical_by_hot_deck(df_imputed)\n",
    "    elif strategy['categorical'] == 'decision_tree':\n",
    "        df_imputed = impute_categorical_by_decision_tree(df_imputed)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown categorical imputation strategy\")\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# Strategy :\n",
    "strategy_delete = {\n",
    "    'numerical': 'delete',\n",
    "    'categorical': 'delete'\n",
    "}\n",
    "\n",
    "strategy_mean_mode = {\n",
    "    'numerical': 'mean',\n",
    "    'categorical': 'mode'\n",
    "}\n",
    "\n",
    "strategy_median_new = {\n",
    "    'numerical': 'median',\n",
    "    'categorical': 'new'\n",
    "}\n",
    "\n",
    "strategy_decision_tree = {\n",
    "    'numerical': 'decision_tree',\n",
    "    'categorical': 'decision_tree'\n",
    "}\n",
    "\n",
    "strategy_mean_new = {\n",
    "    'numerical': 'mean',\n",
    "    'categorical': 'new'\n",
    "}\n",
    "\n",
    "strategy_knn_mode = {\n",
    "    'numerical': 'knn',\n",
    "    'categorical': 'mode'\n",
    "}"
   ],
   "id": "3573d47c4f96b06b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T00:57:15.093496Z",
     "start_time": "2024-08-18T00:20:13.340670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_files(base_path, file_prefix, missing_percentages, strategies):\n",
    "    for percentage in missing_percentages:\n",
    "        # Lire le fichier CSV\n",
    "        df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
    "\n",
    "        # Appliquer chaque stratégie d'imputation et sauvegarder les résultats\n",
    "        for strategy_name, strategy_func, subfolder in strategies:\n",
    "            df_imputed = impute_dataset(df, strategy_func)\n",
    "            df_imputed.to_csv(f\"{base_path}/{subfolder}/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
    "\n",
    "# Les stratégies d'imputation, définies sous forme de tuples avec le nom de la stratégie, la fonction correspondante et le sous-dossier où enregistrer le fichier\n",
    "strategies = [\n",
    "    (\"Delete lines\", strategy_delete, \"Delete lines\"),\n",
    "    (\"Mean and Mode\", strategy_mean_mode, \"Mean and Mode\"),\n",
    "    (\"Median and New\", strategy_median_new, \"Median and New\"),\n",
    "    (\"Decision Tree\", strategy_decision_tree, \"Decision Tree\"),\n",
    "    (\"Mean and New\", strategy_mean_new, \"Mean and New\")\n",
    "    # (\"KNN and Mode\", strategy_knn_mode, \"KNN and Mode\")\n",
    "]\n",
    "\n",
    "missing_percentages = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# Chemins de base pour les différents ensembles de données\n",
    "heart_base_path = \"../../../Data/Classification/Indicators of Heart Disease/Completeness\"\n",
    "retail_base_path = \"../../../Data/Clustering/retail Data/Completeness\"\n",
    "fps_base_path = \"../../../Data/Regression/fps in video games/Completeness\"\n",
    "\n",
    "# Appeler la fonction pour chaque ensemble de données\n",
    "# process_files(heart_base_path, \"heart\", missing_percentages, strategies)\n",
    "# process_files(retail_base_path, \"retail\", missing_percentages, strategies)\n",
    "process_files(fps_base_path, \"fps\", missing_percentages, strategies)"
   ],
   "id": "c3910c0cba028cf5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n",
      "/var/folders/qc/m20c7_k95j52q7xcg6lwyd7w0000gn/T/ipykernel_16808/2976161985.py:4: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{base_path}/NaN/{file_prefix}_{int(percentage * 100)}%.csv\")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "  ",
   "id": "2d9d631bdbda6e9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
